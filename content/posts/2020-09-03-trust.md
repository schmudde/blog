---
title: It's About Trust, Not Privacy
description:
author: David Schmudde
author-email: d@schmud.de
author-url: http://schmud.de
author-github: schmudde
author-twitter: dschmudde
location: Berlin, Germany
date-created: 2020-09-03
date-modified: 2020-09-03
date-published: 2020-09-03
in-language: en
keywords:
tags:
 - suchness
---

People want privacy only when they understand the consequences. Right now, privacy is in fashion. It's possible to offer an alternative. But I'm skeptical about the level of broad, voluntary participation. That's where civic governance can step in. I don't think much about the trust in my food chain.

In [Disinformation Strategies and Tactics](https://schmud.de/posts/2020-05-29-disinformation-strategies.html), I looked at mis/dis/malinformation. Misinformation is the most insidious. It spreads through networks of trust. Powerful orgs can amplify:

<blockquote class="twitter-tweet" data-dnt="true"><p lang="en" dir="ltr">It&#39;s a mistake to attribute it only to the social media team. Dozens of journalists were on duty for NBC last night. They knew how misguided this was. The account broadcasting this pathetic error speaks in the name of the entire news division. But no one took ownership til 1 am. <a href="https://t.co/Glu0Adeth3">pic.twitter.com/Glu0Adeth3</a></p>&mdash; Jay Rosen (@jayrosen_nyu) <a href="https://twitter.com/jayrosen_nyu/status/1296259129166770176?ref_src=twsrc%5Etfw">August 20, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

And it's unclear how to take responsibility. In the case of sharing misinformation about election endorsements or voter fraud, should platforms be held accountable for sharing? Should individuals be removed for sharing even if they do not know better? Should organizations amplifying the message, even if they are reporting it, be held accountable?

## Distributed Trust

[Rachel Botsman](https://rachelbotsman.com/) coined the term distributed trust for this amorphous, shared responsibility between users and platforms - with often asymmetrical power relationships. She concluded that this trust has two speeds: fast and slow.

> Airbnb talks about 'slow trust' and 'fast trust'. Fast trust is when people make their bookings instantly. Slow trust is when people exchange lots of messages with potential hosts and read lots of reviews, and don't instantly book. **You don't want to entirely remove the friction from the trust process, because it means people are actually getting more information, thinking more about their decisions, and thus taking more responsibility in the choices they make.**

Trust is based on either authentication, memory, or intuition. Computers on the world wide web are unable to take intuitive steps, such as "a leap of faith," but perfectly situated to authenticate using cryptographic secrets and remember past actions using &ldquo;cookies&rdquo;.

Lou Montulli first introduced cookies in Netscape Navigator in 1994.[^nyt] The term dates back to at least 1979, appearing in the manual for the [`fseek`](https://en.cppreference.com/w/c/io/fseek) routine in the language C.[^unix][^cookie]

[^nyt]: https://www.nytimes.com/2001/09/04/business/giving-web-a-memory-cost-its-users-privacy.html
[^unix]: UNIX Programmer's Manual, 7th Edition, Vol. 1, FSEEK (3S), Bell Telephone Laboratories, Murray Hill, New Jersey, January 1979. via [Wikipedia](https://en.wikipedia.org/wiki/Magic_cookie)
[^cookie]: As for &ldquo;magic cookie,&rdquo; the source is lost to time. FWIW, [frankie](https://wasteofserver.com/cookie-in-the-jar/) notes the term was used as a euphemism for LSD in the comic strip *Odd Bodkins*, which ran from 1963 to 1970. ![](/img/2020-09-03-trust/odd-bodkins-magic-cookie.jpg)

> `ftell` returns the current value of the offset relative to the beginning of the file associated with the named stream. It is measured in bytes on UNIX; on some other systems it is a **magic cookie**, and the only foolproof way to obtain an offset for `fseek`.

- `fseek` is somewhere in an open file, but it does not have any context. It does not remember where it started, nor does it know where the file ends.
- `ftell` knows the difference between where the file begins and where the function `fseek` currently resides.

Websites are really just streams of data exchanged between a local computer and a remote server. Without cookies, data can only reference its immediate context. There is no long term memory. No one can know where the user began their journey or what they might have saved in their shopping cart two days ago.

Privacy concerns related to cookies became a mainstream issue by the turn of the century. As the [New York Times noted in 2001](https://www.nytimes.com/2001/09/04/business/giving-web-a-memory-cost-its-users-privacy.html):

> In Washington, at least 50 privacy-related bills are awaiting consideration, though the current leadership in the House has focused its attention on privacy invasions by government, not by private business.

For context, the United States' Congress has been passing privacy bills for [a half-century](https://schmud.de/posts/2020-06-15-personal-privacy.html). 50 bills in 2001 is no big deal. The key observation is that the government was not focused on by private business.

The Times insinuates that private businesses like Netscape were also not so interested in privacy.

> Mr. Montulli's first description of cookies can still be found on Netscape's Web site. The document describes how a relatively few bits of text can perform tasks like identifying a visitor, tracking the items he is preparing to buy and setting a date for the cookie to be destroyed. In a whimsical example drawn from Saturday morning cartoons, Mr. Montulli displayed a cookie that might be set on a customer's computer by the fictional Acme Corporation: `Cookie: CUSTOMER=WILE_E_COYOTE; PART_NUMBER= ROCKET_LAUNCHER_0001`
> The document was technically thorough. But one word appears nowhere within it: privacy.

---

![](/img/2020-09-03-trust/truste-1.gif)

Memory introduced new methods for verifying you are who you say you are. And verifying that the $15 that you say is yours is actually exists and indeed belongs to you. Websites could trust us, but it was unclear if we could trust the websites.

[TRUSTe](https://web.archive.org/web/19980122114853/http://www.truste.org/), established in 1997, was one of the first organizations attempting to establish the trustworthiness of sites on the web. It acted as a third party, issuing certificates to websites that met certain requirements. The volunteer-run organization audited sites that displayed the TRUSTe logo to ensure they adhered to their publicly available privacy policy.[^100] From the [About the TRUSTe Privacy Program](https://web.archive.org/web/19980122120530/http://www.truste.org/users/program.html):[^about]

[^100]: Charles Jennings and Lori Fena, *The Hundredth Window* (New York: Free Press, 2000).

> We believe that users should be in charge of disclosing only as much information as they are comfortable with. [...] Knowledge of such practices will empower you to make an informed decision about providing personal information to each individual site.

[^about]: At minimum each site was required to disclose &ldquo;1) What type of information the Web site gathers, 2) how the site uses the information, 3) who the site shares information with, 4) whether you may opt out of having your information used by the site or a third party, 5) whether you may change or update any information once it has been disclosed, and 6) whether you may delete or deactivate yourself from the Web site database.&rdquo;

This is essentially the form of user consent in wide use today.

## Institutional Trust

TRUSTe was an attempt to create a level of institutional trust on the world wide web. **It was a chance for internet companies to govern their own actions**. The TRUSTe badge saw limited adoption[^adoption] as websites increasingly tracked user behavior around the web. These efforts provide immediate financial return through advertising and inform the long term design patterns intended to manipulate user behavior and increase their engagement.

[^adoption]: Companies included everything from peoplematch.com, &ldquo;a free, anonymous, match-making service for friendship and romance,&rdquo; and the GeoCities website hosting service to IBM and the New York Times. For the curious, here is the full [list of TRUSTe companies](https://web.archive.org/web/19980703184141/http://www.truste.com/) in 1998.

Concerned citizens turned to established institutions and asked for help.

Government regulation is the subject of endless criticism from all over the political spectrum. Clay Shirky opined that institutions will tend to preserve the problems for which they offer a solution. It would be dishonest to align Shirky with Ronald Reagan, but this sentiment does ring of the president's famous maxim, &ldquo;Government is not the solution to our problem; government is the problem.&rdquo;

The American government is particularly difficult to trust following the undeniably bogus invasion of Iraq. But military actions - literal life and death decisions - are no more transparent today than when George Bush II was president. This lack of trust is exasperated when the theater of conflict is the internet. What is the proper retaliation for a cyber attack? Does the target matter? The attack on Sony attributed to North Korea, the attack on Iranian centrifuges attributed to the United States and Israel, and the attack on the Democratic National Committee attributed to Russia are very different in scope, style, and consequence. In a democracy, citizens are supposed to have a say if and when their country attacks another state. But even the issue of attribution is incredibly opaque:

> Wasn’t this just the cyber equivalent to the faulty case against Iraq in 2003—when America was also told that the evidence against the Iraqi regime was too sensitive to reveal? Since hacks are notoriously hard to trace, how come the president was so sure about North Korea? Responses such as these revealed how deeply entrenched distrust of America’s intelligence agencies had become in the post-Snowden era.

These are the stakes of trust: life, death, and the foundation of representative democracy. There are only two solutions: new forms of governance or government reforms.

RE: Improving Democracy

Audrey Tang was appointed as the digital minister of Taiwan to build what she calls "a listening society." Many of her initiatives attempt to help people make contributions to government action, which increases trust. Even if you haven't worked on a specific initiative, you may know someone who has. It's a deeper level of civic engagement. This was recently illustrated in her interview on the podcast *[Your Undivided Attention](https://www.humanetech.com/podcast/23-digital-democracy-is-within-reach)*:

> Tristan Harris: Do you have an example of a problem that ultimately found an unlikely consensus? [...] So, unlike our current social media, which sorts for what's most outrageous, which is usually what's most divisive, you're sorting for the opposite.

> Audrey Tang: For example, we just run a few Polis conversations around how to make contact tracing easier. For example, one of the consensus was a health information recorder on your phone, they solve the dilemma that most patients may not recall their whereabouts easily. And, when the medical officers come to them, they may actually accidentally divulge more information about their friends and families. More private details than the contact tracers need to work with. So instead, the app will generate a one-time use link and a dashboard that gives the minimally required information for the medical officer to do their work without compromising their friends' and family's privacy.

> Audrey Tang: It doesn't use Bluetooth or, indeed, any transmitting technology. It's because of that, people would be much more willing to use that sort of tools.

[The State of COVID-19 Exposure Notifications](https://schmud.de/posts/2020-05-07-covid-tracking.html)

Data coalitions form the foundation of another example. AirBox air quality sensor that the Taiwanese connect to a distributed ledger. The sensors came online from the ground up, not from government workers placing them.

> Audrey Tang: Nowadays, hundreds of thousands have contributed. Accumulating a diverse network of, at least, tens of thousands of sensors. Which is closer to the people and provides real-time air quality in the actual places where people are active. That's an enormous amount of environmental data. We put it on the National Center for HighSpeed Computing. We make sure that air products, meteorology, water resource, earthquake, disaster relief and so on, are integrated into this in-place computing environment. All primary schoolers or high schoolers part of slantsphere maybe, can write some code that very quickly run on those on those outside data to discovered correlations between the socio-activities and environmental phenomenon

Culture

> [Facebook keeps] pointing to a flaw, or a system error, or an algorithm, or a bot. And they keep pointing to capability solutions: 'We've now introduced this tool or that mechanism.'

> What they do not talk about is character, and you see this mistake time and time again. Social scientist Diego Gambetta says the enemies of trust are bad character and poor information. I can't trust Facebook again until I feel like something has fundamentally changed in their character and culture.

Ben Thompson: culture is the thing that brought the success. so it can’t change until it’s too late. Facebook is ripe for disruption.

> Boeing is a different example than Facebook. With the 737 MAX, all the messaging from the previous CEO, Dennis Muilenberg, was about 'system error' and 'flaws in the system: The new CEO, on the other hand, is saying, 'No, what caused this mess was actually a cultural problem - us, the leadership, and people.

RE: Facebook as an institution

> My assumption would be they talk about 'building trust; and ask questions like, 'How have we built trust this quarter?' That, to me, would be a powerful indicator that Facebook think trust is something they can control versus it being something that users give to them. There is a big shift when leaders realize they need to do everything they can to earn trust back - but that it's the users who will decide whether or when that happens

--- ---

https://theglassroom.org/misinformation/



---

- [Renee Diresta](http://www.reneediresta.com/#speaking)
            - @ Stanford IO
            - Renee DiResta, Mozilla Fellow in Media, Misinformation and Trust, speaks at MozFest 2018. Renee investigates the spread of disinformation and manipulated narratives across social networks.
            - w/ Joe Rogan: https://www.youtube.com/watch?v=UAGZcGi1OP8

In an era of WMD's, how do you trust these attributions?

> “This was a destructive attack,” said Robert Litt, the general counsel for the director of national intelligence. “But you couldn’t argue that it hit a vital sector of the US infrastructure. It wasn’t exactly taking out all the power from Boston to Washington. So the issue was: is this the government’s responsibility to defend?”

> a long-simmering debate about the advisability of letting companies go beyond building bigger defenses to actually striking back themselves at their attackers—something called “hacking back.” It’s illegal, just as it’s illegal to break into the house of someone who robbed your house in order to retrieve your own property.



[The Evolution of Trust](http://ncase.me/trust/) by Nicky Case


When Audrey Tang was appointed as the digital minister of Taiwan, she set out to build a "listening society."[^tang] I'm cautiously encouraged by her early results. Although the technology's application may be novel, it is rooted in the basic human character. She is finding creative ways to involve average citizens in the process of building a strong community. People want to feel heard. They want their hard work to matter. Guiding an open community project is more than just a technological endeavor; it is the responsibility of building a culture larger than its parts.

[^tang]: Tristan Harris, "[Digital Democracy Is Within Reach (Episode 22)](https://www.humanetech.com/podcast/23-digital-democracy-is-within-reach)", podcast, *Your Undivided Attention*, 2020.



# [What makes fake news feel true when it isn’t? For one thing, hearing it over and over again](https://www.niemanlab.org/2020/08/what-makes-fake-news-feel-true-when-it-isnt-for-one-thing-hearing-it-over-and-over-again/)

https://www.taylorfrancis.com/books/e/9780429295379


> When it comes to cookies, he says that he is satisfied with the way things have worked out. Even though he does not favor the use of third-party cookies, he calls the existence of third-party cookies ''the best possible error,'' because ''the only way it could be exploited is by someone who is extremely public, who is extremely large and who has a very long reach'' -- a company, in other words, that cannot afford a public relations fiasco, he said.
